{"name":"Machine learning course","tagline":"Coursera Machine Learning Course Project","body":"### Brief introduction\r\n\r\nIn the report we’ll try to build a model for predicting “how (well)” an lifting activity was performed by the wearer(of devices such as Jawbone Up, Nike FuelBand, and Fitbit) using ‘Weight Lifting Exercises Dataset’.\r\n\r\nSix young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).\r\n\r\nThanks and respect these guys for data sharing:\r\n\r\n+ Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting + Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human ’13) . Stuttgart, Germany: ACM SIGCHI, 2013.\r\n\r\n### Data loading and preprocessing\r\n\r\nAt first lets include all the required libraries\r\n```\r\nlibrary(caret)\r\nlibrary(ggplot2)\r\nlibrary(dplyr)\r\n```\r\nand load data into the R:\r\n```\r\n# Don't be confused. I have MatLab and R projects in the same folder :)\r\nsetwd('C:\\\\Users\\\\Dmi\\\\Desktop\\\\MatLab\\\\Coursera\\\\MachineLearning')\r\ndata.train <- read.csv('pml-training.csv')\r\ndata.test <- read.csv('pml-testing.csv')\r\n```\r\nNow lets see what the training data we have using ```glimpse``` from ```dplyr``` package. I give the code, but the output is to big to include:\r\n```\r\nglimpse(data.train)\r\n```\r\nFrom the ```glimpse``` output we can see that there are 160 different variables and a lot of variables are with NAs or have empty values. Lets clean our data from these ‘bad’ variables. Also lets delete first 5 variables from the data (row number, username and 3 timestamps) and omit all the residual rows with NAs. We preprocess both train and test data similary:\r\n```\r\n# deleting zero variance variables\r\nzeroVar <- nearZeroVar(data.train)\r\ndata.train <- data.train[,-zeroVar]\r\ndata.test <- data.test[, -zeroVar]\r\n# deleting variables with many NAs\r\nmanyNAs <- sapply(data.train, function(x){\r\n                                          sum(as.integer(is.na(x))) > 19000\r\n                                         })\r\ndata.train <- data.train[,!manyNAs]\r\ndata.test <- data.test[, !manyNAs]\r\n# deleting row number, user_name, raw_timestamp_part_#, cvtd_timestamp\r\ndata.train <- data.train[,-c(1:5)]\r\ndata.test <- data.test[, -c(1:5)]\r\n# omit all rows with NAs\r\ndata.train <- na.omit(data.train)\r\ndata.test <- na.omit(data.test)\r\n```\r\nNow lets look at he cleaned data. Again I give the code but don’t include output because of big size.\r\n```\r\nglimpse(data.train)\r\n```\r\nWe won’t center and scale data because Random Forest algorithm which we’ll use is rather stable with unscaled data.\r\n\r\n### Building model\r\n\r\nNow we have our data cleaned and with 53 variables instead of 160. Our task is to build a classification model. We’ll use a Random Forest algorithm for the task. At first lets split our data into two pieces (training and test). For training data we’ll take 0.7 of the original data and the rest part will be for testing.\r\n\r\n```\r\ntrain <- createDataPartition(data.train$classe, p = 0.7, list=F)\r\ntrain.train <- data.train[train,]\r\ntrain.test <- data.train[-train,]\r\n```\r\nNow time to create formula and start training our model. We’ll make 20-fold cross validation with 4 repeats:\r\n```\r\ntrFormula <- classe ~ .\r\ntrControl <- trainControl(method='cv', number = 20, repeats = 4)\r\ntrain.rf <- train(trFormula, trControl=trControl, data = train.train )\r\n```\r\nAfter some time we have our model trained. Lets look at the top important variables of the model:\r\n```\r\nhead(varImp(train.rf)[[1]])\r\n```\r\n```\r\n##                      Overall\r\n## num_window       100.0000000\r\n## roll_belt         64.0773568\r\n## pitch_belt        28.3311490\r\n## yaw_belt          32.3988043\r\n## total_accel_belt   2.0684927\r\n## gyros_belt_x       0.9213126\r\n```\r\n\r\n\r\n\r\n\r\n\r\n<script>\r\n  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\r\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\r\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\r\n  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');\r\n\r\n  ga('create', 'UA-62278086-1', 'auto');\r\n  ga('send', 'pageview');\r\n\r\n</script>\r\n","google":"UA-62278086-1","note":"Don't delete this file! It's used internally to help with page regeneration."}