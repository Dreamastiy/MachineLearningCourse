{"name":"Machine learning course","tagline":"Coursera Machine Learning Course Project","body":"### Brief introduction\r\n\r\nIn the report we’ll try to build a model for predicting “how (well)” an lifting activity was performed by the wearer(of devices such as Jawbone Up, Nike FuelBand, and Fitbit) using ‘Weight Lifting Exercises Dataset’.\r\n\r\nSix young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).\r\n\r\nThanks and respect these guys for data sharing:\r\n\r\n+ Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting + Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human ’13) . Stuttgart, Germany: ACM SIGCHI, 2013.\r\n\r\n### Data loading and preprocessing\r\n\r\nAt first lets include all the required libraries\r\n```\r\nlibrary(caret)\r\nlibrary(ggplot2)\r\nlibrary(dplyr)\r\n```\r\nand load data into the R:\r\n```\r\n# Don't be confused. I have MatLab and R projects in the same folder :)\r\nsetwd('C:\\\\Users\\\\Dmi\\\\Desktop\\\\MatLab\\\\Coursera\\\\MachineLearning')\r\ndata.train <- read.csv('pml-training.csv')\r\ndata.test <- read.csv('pml-testing.csv')\r\n```\r\nNow lets see what the training data we have using ```glimpse``` from ```dplyr``` package. I give the code, but the output is to big to include:\r\n```\r\nglimpse(data.train)\r\n```\r\nFrom the ```glimpse``` output we can see that there are 160 different variables and a lot of variables are with NAs or have empty values. Lets clean our data from these ‘bad’ variables. Also lets delete first 5 variables from the data (row number, username and 3 timestamps) and omit all the residual rows with NAs. We preprocess both train and test data similary:\r\n```\r\n# deleting zero variance variables\r\nzeroVar <- nearZeroVar(data.train)\r\ndata.train <- data.train[,-zeroVar]\r\ndata.test <- data.test[, -zeroVar]\r\n# deleting variables with many NAs\r\nmanyNAs <- sapply(data.train, function(x){\r\n                                          sum(as.integer(is.na(x))) > 19000\r\n                                         })\r\ndata.train <- data.train[,!manyNAs]\r\ndata.test <- data.test[, !manyNAs]\r\n# deleting row number, user_name, raw_timestamp_part_#, cvtd_timestamp\r\ndata.train <- data.train[,-c(1:5)]\r\ndata.test <- data.test[, -c(1:5)]\r\n# omit all rows with NAs\r\ndata.train <- na.omit(data.train)\r\ndata.test <- na.omit(data.test)\r\n```\r\nNow lets look at he cleaned data. Again I give the code but don’t include output because of big size.\r\n```\r\nglimpse(data.train)\r\n```\r\n\r\n\r\n\r\n<script>\r\n  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){\r\n  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),\r\n  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)\r\n  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');\r\n\r\n  ga('create', 'UA-62278086-1', 'auto');\r\n  ga('send', 'pageview');\r\n\r\n</script>\r\n","google":"UA-62278086-1","note":"Don't delete this file! It's used internally to help with page regeneration."}