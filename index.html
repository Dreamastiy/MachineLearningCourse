<!DOCTYPE html>
<html>
  <head>
    <meta charset='utf-8'>
    <meta http-equiv="X-UA-Compatible" content="chrome=1">

    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/pygment_trac.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/print.css" media="print">

    <title>Machine learning course by Dreamastiy</title>
  </head>

  <body>

    <header>
      <div class="container">
        <h1>Machine learning course</h1>
        <h2>Coursera Machine Learning Course Project</h2>

        <section id="downloads">
          <a href="https://github.com/Dreamastiy/MachineLearningCourse/zipball/master" class="btn">Download as .zip</a>
          <a href="https://github.com/Dreamastiy/MachineLearningCourse/tarball/master" class="btn">Download as .tar.gz</a>
          <a href="https://github.com/Dreamastiy/MachineLearningCourse" class="btn btn-github"><span class="icon"></span>View on GitHub</a>
        </section>
      </div>
    </header>

    <div class="container">
      <section id="main_content">
        <h3>
<a id="brief-introduction" class="anchor" href="#brief-introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>Brief introduction</h3>

<p>In the report we’ll try to build a model for predicting “how (well)” an lifting activity was performed by the wearer(of devices such as Jawbone Up, Nike FuelBand, and Fitbit) using ‘Weight Lifting Exercises Dataset’.</p>

<p>Six young health participants were asked to perform one set of 10 repetitions of the Unilateral Dumbbell Biceps Curl in five different fashions: exactly according to the specification (Class A), throwing the elbows to the front (Class B), lifting the dumbbell only halfway (Class C), lowering the dumbbell only halfway (Class D) and throwing the hips to the front (Class E).</p>

<p>Thanks and respect these guys for data sharing:</p>

<ul>
<li>Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting + Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human ’13) . Stuttgart, Germany: ACM SIGCHI, 2013.</li>
</ul>

<h3>
<a id="data-loading-and-preprocessing" class="anchor" href="#data-loading-and-preprocessing" aria-hidden="true"><span class="octicon octicon-link"></span></a>Data loading and preprocessing</h3>

<p>At first lets include all the required libraries</p>

<div class="highlight highlight-r"><pre>library(<span class="pl-smi">caret</span>)
library(<span class="pl-smi">ggplot2</span>)
library(<span class="pl-smi">dplyr</span>)</pre></div>

<p>and load data into the R:</p>

<div class="highlight highlight-r"><pre><span class="pl-c"># Don't be confused. I have MatLab and R projects in the same folder :)</span>

setwd(<span class="pl-s"><span class="pl-pds">'</span>C:<span class="pl-cce">\\</span>Users<span class="pl-cce">\\</span>Dmi<span class="pl-cce">\\</span>Desktop<span class="pl-cce">\\</span>MatLab<span class="pl-cce">\\</span>Coursera<span class="pl-cce">\\</span>MachineLearning<span class="pl-pds">'</span></span>)
<span class="pl-smi">data.train</span> <span class="pl-k">&lt;-</span> read.csv(<span class="pl-s"><span class="pl-pds">'</span>pml-training.csv<span class="pl-pds">'</span></span>)
<span class="pl-smi">data.test</span> <span class="pl-k">&lt;-</span> read.csv(<span class="pl-s"><span class="pl-pds">'</span>pml-testing.csv<span class="pl-pds">'</span></span>)</pre></div>

<p>Now lets see what the training data we have using <code>glimpse</code> from <code>dplyr</code> package. I give the code, but the output is to big to include:</p>

<div class="highlight highlight-r"><pre>glimpse(<span class="pl-smi">data.train</span>)</pre></div>

<p>From the <code>glimpse</code> output we can see that there are 160 different variables and a lot of variables are with NAs or have empty values. Lets clean our data from these ‘bad’ variables. Also lets delete first 5 variables from the data (row number, username and 3 timestamps) and omit all the residual rows with NAs. We preprocess both train and test data similary:</p>

<div class="highlight highlight-r"><pre><span class="pl-c"># deleting zero variance variables</span>
<span class="pl-smi">zeroVar</span> <span class="pl-k">&lt;-</span> nearZeroVar(<span class="pl-smi">data.train</span>)
<span class="pl-smi">data.train</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">data.train</span>[,<span class="pl-k">-</span><span class="pl-smi">zeroVar</span>]
<span class="pl-smi">data.test</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">data.test</span>[, <span class="pl-k">-</span><span class="pl-smi">zeroVar</span>]

<span class="pl-c"># deleting variables with many NAs</span>
<span class="pl-smi">manyNAs</span> <span class="pl-k">&lt;-</span> sapply(<span class="pl-smi">data.train</span>, <span class="pl-k">function</span>(<span class="pl-smi">x</span>){
                                          sum(as.integer(is.na(<span class="pl-smi">x</span>))) <span class="pl-k">&gt;</span> <span class="pl-c1">19000</span>
                                         })
<span class="pl-smi">data.train</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">data.train</span>[,<span class="pl-k">!</span><span class="pl-smi">manyNAs</span>]
<span class="pl-smi">data.test</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">data.test</span>[, <span class="pl-k">!</span><span class="pl-smi">manyNAs</span>]

<span class="pl-c"># deleting row number, user_name, raw_timestamp_part_#, cvtd_timestamp</span>
<span class="pl-smi">data.train</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">data.train</span>[,<span class="pl-k">-</span>c(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">5</span>)]
<span class="pl-smi">data.test</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">data.test</span>[, <span class="pl-k">-</span>c(<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">5</span>)]

<span class="pl-c"># omit all rows with NAs</span>
<span class="pl-smi">data.train</span> <span class="pl-k">&lt;-</span> na.omit(<span class="pl-smi">data.train</span>)
<span class="pl-smi">data.test</span> <span class="pl-k">&lt;-</span> na.omit(<span class="pl-smi">data.test</span>)</pre></div>

<p>Now lets look at he cleaned data. Again I give the code but don’t include output because of big size.</p>

<div class="highlight highlight-r"><pre>glimpse(<span class="pl-smi">data.train</span>)</pre></div>

<p>We won’t center and scale data because Random Forest algorithm which we’ll use is rather stable with unscaled data.</p>

<h3>
<a id="building-model" class="anchor" href="#building-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Building model</h3>

<p>Now we have our data cleaned and with 53 variables instead of 160. Our task is to build a classification model. We’ll use a Random Forest algorithm for the task. At first lets split our data into two pieces (training and test). For training data we’ll take 0.7 of the original data and the rest part will be for testing.</p>

<div class="highlight highlight-r"><pre><span class="pl-smi">train</span> <span class="pl-k">&lt;-</span> createDataPartition(<span class="pl-smi">data.train</span><span class="pl-k">$</span><span class="pl-smi">classe</span>, <span class="pl-v">p</span> <span class="pl-k">=</span> <span class="pl-c1">0.7</span>, <span class="pl-v">list</span><span class="pl-k">=</span><span class="pl-c1">F</span>)
<span class="pl-smi">train.train</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">data.train</span>[<span class="pl-smi">train</span>,]
<span class="pl-smi">train.test</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">data.train</span>[<span class="pl-k">-</span><span class="pl-smi">train</span>,]</pre></div>

<p>Now time to create formula and start training our model. We’ll make 20-fold cross validation with 4 repeats:</p>

<div class="highlight highlight-r"><pre><span class="pl-smi">trFormula</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">classe</span> <span class="pl-k">~</span> .
<span class="pl-smi">trControl</span> <span class="pl-k">&lt;-</span> trainControl(<span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">'</span>cv<span class="pl-pds">'</span></span>, <span class="pl-v">number</span> <span class="pl-k">=</span> <span class="pl-c1">20</span>, <span class="pl-v">repeats</span> <span class="pl-k">=</span> <span class="pl-c1">4</span>)
<span class="pl-smi">train.rf</span> <span class="pl-k">&lt;-</span> train(<span class="pl-smi">trFormula</span>, <span class="pl-v">trControl</span><span class="pl-k">=</span><span class="pl-smi">trControl</span>, <span class="pl-v">data</span> <span class="pl-k">=</span> <span class="pl-smi">train.train</span> )</pre></div>

<p>After some time we have our model trained. Lets look at the top important variables of the model:</p>

<div class="highlight highlight-r"><pre>head(varImp(<span class="pl-smi">train.rf</span>)[[<span class="pl-c1">1</span>]])</pre></div>

<pre><code>##                      Overall
## num_window         100.00000
## roll_belt          64.077356
## pitch_belt         28.331149
## yaw_belt           32.398804
## total_accel_belt   2.0684927
## gyros_belt_x       0.9213126
</code></pre>

<p>Now lets look at a confusion matrix and plot error rate:</p>

<div class="highlight highlight-r"><pre>confusionMatrix(predict(<span class="pl-smi">train.rf</span>, <span class="pl-smi">train.train</span>), <span class="pl-smi">train.train</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)</pre></div>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 3906    3    0    0    0
##          B    0 2655    0    0    0
##          C    0    0 2394    4    0
##          D    0    0    2 2248    0
##          E    0    0    0    0 2525
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9993          
##                  95% CI : (0.9988, 0.9997)
##     No Information Rate : 0.2843          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9992          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            1.0000   0.9989   0.9992   0.9982   1.0000
## Specificity            0.9997   1.0000   0.9996   0.9998   1.0000
## Pos Pred Value         0.9992   1.0000   0.9983   0.9991   1.0000
## Neg Pred Value         1.0000   0.9997   0.9998   0.9997   1.0000
## Prevalence             0.2843   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2843   0.1933   0.1743   0.1636   0.1838
## Detection Prevalence   0.2846   0.1933   0.1746   0.1638   0.1838
## Balanced Accuracy      0.9998   0.9994   0.9994   0.9990   1.0000
</code></pre>


      </section>
    </div>

              <script type="text/javascript">
            var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
            document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
          </script>
          <script type="text/javascript">
            try {
              var pageTracker = _gat._getTracker("UA-62278086-1");
            pageTracker._trackPageview();
            } catch(err) {}
          </script>

  </body>
</html>